Bert-base_for_TensorFlow
1 交付件基本信息
发布者（Publisher）：Huawei
应用领域（Application Domain）：NLP
版本（Version）：1.2
修改时间（Modified）：2020.10.14
大小（Size）：
框架（Framework）：TensorFlow 1.15.0
模型格式（Model Format）：ckpt
精度（Precision）：Mixed
处理器（Processor）：昇腾910
应用级别（Categories）：Benchmark
描述（Description）：基于TensorFlow框架的BERT-Base及下游任务代码

2、概述
BERT是谷歌2018年推出的预训练语言模型结构，通过自监督训练实现对语义语境相关的编码，是目前众多NLP应用的基石。

参考论文：Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.

参考实现：https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/LanguageModeling/BERT

适配昇腾 AI 处理器的实现：
```
        url=https://gitee.com/ascend/modelzoo.git
        branch=master
        commit_id=9887f0b4ae27f16a1e9f8b0a94dda87b0bf8430a
        code_path=built-in\TensorFlow\Official\cv\image_classification\AlexNet_for_TensorFlow
        ```


    通过Git获取对应commit\_id的代码方法如下：
    
    ```
    git clone {repository_url}    # 克隆仓库的代码
    cd {repository_name}    # 切换到模型的代码仓目录
    git checkout  {branch}    # 切换到对应分支
    git reset --hard ｛commit_id｝     # 代码设置到对应的commit_id
    cd ｛code_path｝    # 切换到模型代码所在路径，若仓库下只有该模型，则无需切换
	
	_Official__（商用版）：在昇腾AI__处理器有良好的精度和性能表现_

默认配置网络结构
学习率为1e-5，使用polynomial decay
优化器：Adam
优化器Weight decay为0.01
优化器epsilon设置为1e-4
单卡batchsize：128
32卡batchsize：128*32
总step数设置为500000
Warmup step设置为10000
训练数据集预处理（以wikipedia为例，仅作为用户参考示例）：
Sequence Length原则上用户可以自行定义。以常见的设置128为例，mask其中的20个tokens作为自编码恢复的目标。
下游任务预处理以用户需要为准。
测试数据集预处理（以wikipedia为例，仅作为用户参考示例）：
与训练数据集处理一致。
支持特性支持的特性包括：1、分布式训练。2、混合精度。3、数据并行。8P训练脚本，支持数据并行的分布式训练。脚本样例中默认开启了混合精度，参考示例，见“开启混合精度”。

混合精度训练昇腾910 AI处理器提供自动混合精度功能，可以针对全网中float32数据类型的算子，按照内置的优化策略，自动将部分float32的算子降低精度到float16，从而在精度损失很小的情况下提升系统性能并减少内存使用。
开启混合精度相关代码示例。
run_config = NPURunConfig(
        model_dir=self.config.model_dir,
        session_config=session_config,
        keep_checkpoint_max=5,
        save_checkpoints_steps=5000,
        enable_data_pre_proc=True,
        iterations_per_loop=iterations_per_loop,
        precision_mode='allow_mix_precision',
        hcom_parallel=True      ）
		
3、训练环境准备[TensorFlow]
硬件环境准备请参见各硬件产品文档。需要在硬件设备上安装与CANN版本配套的固件与驱动。
宿主机上需要安装Docker并登录Ascend Hub中心获取镜像。当前模型支持的镜像列表如下表所示。
镜像名称：ARM架构：ascend-tensorflow-arm及x86 架构：ascend-tensorflow-x86
镜像版本：20.1.020.2.0
配套CANN版本:20.120.2
说明：对应配套华为企业业务网站 （ http://support.huawei.com ） “技术支持 > 昇腾计算 > 解决方案配套与软件 > CANN”的“V100R020C10V100R020C20”版本号。

4、快速上手
数据集准备
数据集以文本格式表示，每段之间以空行隔开。源码包目录下“data/pretrain-toy/”给出了sample_text以及处理后的样例tfrecord数据集，如wikipedia。
运行如下命令，将数据集转换为tfrecord格式。
python utils/create_pretraining_data.py \   
  --input_file=./your/path/some_input_data.txt \   
  --output_file=/data/some_output_data.tfrecord \   
  --vocab_file=./your/path/vocab.txt \   
  --do_lower_case=True \   
  --max_seq_length=128 \   
  --max_predictions_per_seq=20 \   
  --masked_lm_prob=0.15 \   
  --random_seed=12345 \   
  --dupe_factor=5

模型训练
单击“立即下载”，下载源码包。
编译镜像。
docker build -t ascend-bert .
启动容器实例。
bash scripts/docker_start.sh
容器启动脚本docker_start.sh参数说明如下：
#!/usr/bin/env bash
docker_image=$1 \#接受第一个参数作为docker_image
data_dir=$2 \#接受第二个参数作为训练数据集路径
model_dir=$3 \#接受第三个参数作为训练脚本路径
docker run -it --ipc=host \
        --device=/dev/davinci0 --device=/dev/davinci1 --device=/dev/davinci2 --device=/dev/davinci3 --device=/dev/davinci4 --device=/dev/davinci5 --device=/dev/davinci6 --device=/dev/davinci7 \  #docker使用卡数，当前使用0~7卡
 --device=/dev/davinci_manager --device=/dev/devmm_svm --device=/dev/hisi_hdc \
        -v /usr/local/Ascend/driver:/usr/local/Ascend/driver -v /usr/local/Ascend/add-ons/:/usr/local/Ascend/add-ons/ \
        -v ${data_dir}:${data_dir} \    #训练数据集路径
        -v ${model_dir}:${model_dir} \  #训练脚本路径
        -v /var/log/npu/conf/slog/slog.conf:/var/log/npu/conf/slog/slog.conf \
        -v /var/log/npu/slog/:/var/log/npu/slog -v /var/log/npu/profiling/:/var/log/npu/profiling \
        -v /var/log/npu/dump/:/var/log/npu/dump -v /var/log/npu/:/usr/slog ${docker_image} \#docker_image为镜像名称
        /bin/bash
执行docker_start.sh后带三个参数：
生成的docker_image
数据集路径
训练脚本路径
./docker_start.sh ${docker_image} ${data_dir} ${model_dir}
启动训练之前，首先要配置程序运行相关环境变量。环境变量配置信息示例内容如下。
当版本为Atlas Data Center Solution V100R020C00时，请使用以下环境变量：

#!/bin/bash
export install_path=/usr/local/Ascend
export PATH=${install_path}/nnae/latest/fwkacllib/ccec_compiler/bin:${PATH}
export ASCEND_OPP_PATH=${install_path}/nnae/latest/opp
export PYTHONPATH=$PYTHONPATH:${install_path}/nnae/latest/opp/op_impl/built-in/ai_core/tbe:${install_path}/tfplugin/latest/tfplugin/python/site-packages/:${install_path}/nnae/latest/fwkacllib/python/site-packages/hccl:${install_path}/nnae/latest/fwkacllib/python/site-packages/te:${install_path}/nnae/latest/fwkacllib/python/site-packages/topi
export LD_LIBRARY_PATH=/usr/local/:/usr/local/lib/:/usr/lib/:${install_path}/nnae/latest/fwkacllib/lib64/:${install_path}/driver/lib64/common/:${install_path}/driver/lib64/driver/:${install_path}/add-ons
当版本为Atlas Data Center Solution V100R020C10时，请使用以下环境变量：
export install_path=/usr/local/Ascend/nnae/latest
# driver包依赖
export LD_LIBRARY_PATH=/usr/local/Ascend/driver/lib64/common/:/usr/local/Ascend/driver/lib64/driver:$LD_LIBRARY_PATH #仅容器训练场景配置
export LD_LIBRARY_PATH=/usr/local/Ascend/add-ons:$LD_LIBRARY_PATH
#fwkacllib 包依赖
export LD_LIBRARY_PATH=${install_path}/fwkacllib/lib64:$LD_LIBRARY_PATH
export 
PYTHONPATH=${install_path}/fwkacllib/python/site-packages:${install_path}/fwkacllib/python/site-packages/auto_tune.egg/auto_tune:${install_path}/fwkacllib/python/site-packages/schedule_search.egg:$PYTHONPATH
export
PATH=${install_path}/fwkacllib/ccec_compiler/bin:${install_path}/fwkacllib/bin:$PATH
#tfplugin 包依赖
export PYTHONPATH=/usr/local/Ascend/tfplugin/latest/tfplugin/python/site-packages:$PYTHONPATH
# opp包依赖
export ASCEND_OPP_PATH=${install_path}/opp
开始训练。
单卡训练
cd scripts
./run_pretraining.sh
8卡训练
cd scripts
./run_8p.sh
下游任务Finetune。
提供三个脚本，分别是文本分类任务，序列标注任务，阅读理解任务，并且提供了XNLI，LCQMC，CHNSENTI，NER，CMRC的数据处理方法示例，用户可根据自己的下游任务需要改写和处理数据。然后运行脚本，参考超参已经写入脚本供用户参考。
执行命令：
bash scripts/run_downstream_classifier.sh进行分类下游任务。
bash scripts/run_downstream_ner.sh进行序列标注下游任务。
bash scripts/run_downstream_reading.sh进行阅读理解下游任务。执行命令前请先阅读相应bash脚本，补充相应文件路径。
高级参考
脚本和示例代码├── configs  
│    ├──BERT_base_64p_poc.json              //8*8p rank table配置文件
│    ├──nezha_large_config.json               //NEZHA large模型配置文件
│    ├──nezha_large_vocab.txt                 //NEZHA large中文词表
├── scripts
│    ├──npu_set_env.sh                         //集群配置
│    ├──run_downstream_classifier.sh           //运行下游任务分类器
│    ├──run_downstream_ner.sh                  //运行下游任务序列标注
│    ├──run_downstream_reading.sh              //运行下游任务阅读理解
│    ├──run_pretraining.sh                     //单卡预训练脚本
│    ├──run_8p.sh                              //8卡预训练入口脚本
│    ├──train_8p.sh                            //8卡预训练脚本  
├── src/downstream
│    ├──gpu_environment.py                     //原始gpu_environment设置
│    ├──metrics_impl.py                       //适配NPU后的metrics_impl.py
│    ├──modeling.py                           //NEZHA模型脚本
│    ├──optimization.py                       //优化器脚本
│    ├──reading_evaluate.py                   //阅读理解评价脚本
│    ├──run_classifier.py                     //下游任务分类脚本
│    ├──run_ner.py                           //下游任务序列标注脚本
│    ├──run_reading.py                         //下游任务阅读理解脚本
│    ├──tf_metrics.py                        //tf metrics脚本
│    ├──tokenization.py                      //分词器脚本
├── src/pretrain
│    ├──gpu_environment.py                     //原始gpu_environment设置
│    ├──create_pretraining_data.py            //生成与训练数据脚本
│    ├──modeling.py                           //NEZHA模型脚本
│    ├──optimization.py                       //优化器脚本
│    ├──extract_features.py                   //特征抽取脚本
│    ├──fp16_utils.py                       //fp16 utils脚本
│    ├──fused_layer_norm.py                     //layer norm融合脚本
│    ├──run_pretraining.py                    //预训练启动脚本
│    ├──tf_metrics.py                        //tf metrics脚本
│    ├──tokenization.py                      //分词器脚本
│    ├──utils.py                            //utils脚本├── CONTRIBUTING.md                             //CONTRIBUTING.md
├── src/downstream
│    ├──gpu_environment.py                     //原始gpu_environment设置
│    ├──metrics_impl.py                       //适配NPU后的metrics_impl.py
│    ├──modeling.py                           //NEZHA模型脚本
│    ├──optimization.py                       //优化器脚本
│    ├──reading_evaluate.py                   //阅读理解评价脚本
│    ├──run_classifier.py                     //下游任务分类脚本
│    ├──run_ner.py                           //下游任务序列标注脚本
│    ├──run_reading.py                         //下游任务阅读理解脚本
│    ├──tf_metrics.py                        //tf metrics脚本
│    ├──tokenization.py                      //分词器脚本
├── src/pretrain
│    ├──gpu_environment.py                     //原始gpu_environment设置
│    ├──create_pretraining_data.py            //生成与训练数据脚本
│    ├──modeling.py                           //NEZHA模型脚本
│    ├──optimization.py                       //优化器脚本
│    ├──extract_features.py                   //特征抽取脚本
│    ├──fp16_utils.py                       //fp16 utils脚本
│    ├──fused_layer_norm.py                     //layer norm融合脚本
│    ├──run_pretraining.py                    //预训练启动脚本
│    ├──tf_metrics.py                        //tf metrics脚本
│    ├──tokenization.py                      //分词器脚本
│    ├──utils.py                            //utils脚本
├── CONTRIBUTING.md                             //CONTRIBUTING.md
├── LICENCE                                   //LICENCE
├── NOTICE                                   //NOTICE├── README.md                                 //说明文档

获取数据
如果要使用自己的数据集，请参考上述数据处理部分自行处理数据。
该数据集的训练过程脚本只作为一种参考示例。
训练过程
通过“快速上手”中的训练指令启动训练。
I0521 19:45:05.731803 281473752813584 basic_session_run_hooks.py:692] global_step/sec: 2.451
I0521 19:45:05.732023 281473228546064 basic_session_run_hooks.py:260] global_step = 1323600, masked_lm_loss = 0.7687549, next_sentence_loss = 0.005564222, total_loss = 0.7743191 (81.600 sec)
I0521 19:45:05.732058 281473117769744 basic_session_run_hooks.py:260] global_step = 1323600, masked_lm_loss = 0.74314255, next_sentence_loss = 0.023222845, total_loss = 0.7663654 (81.600 sec)
2020-05-21 19:45:05.732132: I tf_adapter/kernels/geop_npu.cc:526] [GEOP] RunGraphAsync callback, status:0, kernel_name:GeOp15_0[ 2409us]
I0521 19:45:05.732016 281473584246800 basic_session_run_hooks.py:692] global_step/sec: 2.451
I0521 19:45:05.732048 281472971046928 basic_session_run_hooks.py:692] global_step/sec: 2.451
loss_scale: loss_scale:[65536.0] [65536.0]
2020-05-21 19:45:05.732378: I tf_adapter/kernels/geop_npu.cc:526] [GEOP] RunGraphAsync callback, status:0, kernel_name:GeOp15_0[ 2445us]
loss_scale: I0521 19:45:05.732480 281473752813584 basic_session_run_hooks.py:260] global_step = 1323600, masked_lm_loss = 0.94164073, next_sentence_loss = 0.023505606, total_loss = 0.96514636 (81.600 sec)
[65536.0]
I0521 19:45:05.732715 281473584246800 basic_session_run_hooks.py:260] global_step = 1323600, masked_lm_loss = 0.738043, next_sentence_loss = 0.03810045, total_loss = 0.77614343 (81.599 sec)
I0521 19:45:05.732658 281473385623568 basic_session_run_hooks.py:692] global_step/sec: 2.451
I0521 19:45:05.732574 281473416220688 basic_session_run_hooks.py:692] global_step/sec: 2.45098
I0521 19:45:05.732777 281472971046928 basic_session_run_hooks.py:260] global_step = 1323600, masked_lm_loss = 0.7797201, next_sentence_loss = 0.05669275, total_loss = 0.8364129 (81.600 sec)loss_scale: [65536.0]
loss_scale: I0521 19:45:05.733291 281473385623568 basic_session_run_hooks.py:260] global_step = 1323600, masked_lm_loss = 0.8004036, next_sentence_loss = 0.12787658, total_loss = 0.9282802 (81.600 sec)[65536.0]
调优过程
通过“快速上手”中的调优说明，对自己的下游任务进行调优和预测。
验证/推理过程
见下游任务Finetune。

ResNext50_for_TensorFlow

1、交付件基本信息
发布者（Publisher）：Huawei
应用领域（Application Domain）：Classification
版本（Version）：1.2
修改时间（Modified）：2020.10.14
大小（Size）：221M
框架（Framework）：TensorFlow 1.15.0
模型格式（Model Format）：ckpt
精度（Precision）：Mixed
处理器（Processor）：昇腾910
应用级别（Categories）：Official
描述（Description）：基于TensorFlow框架的ResNeXt-50图像分类网络训练代码

2、 概述
简述ResNeXt网络在ResNet基础上进行了优化，同时采用Vgg/ResNet堆叠的思想和Inception的split-transform-merge思想，把单路卷积转变成了多个支路的多个卷积。ResNeXt结构可以在不增加参数复杂度的前提下提高准确率，同时还减少了超参数的数量。ResNeXt有不同的网络层数，常用的有18-layer、34-layer、50-layer、101-layer、152-layer。Ascend本次提供的是50-layer的ResNeXt-50网络。
参考论文：Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He.Aggregated Residual Transformations for Deep Neural Networks   https://arxiv.org/abs/1611.05431
参考实现：https://pytorch.org/docs/stable/_modules/torchvision/models/alexnet.html#alexnet
适配昇腾 AI 处理器的实现：
```
        url=https://gitee.com/ascend/modelzoo.git
        branch=master
        commit_id=9887f0b4ae27f16a1e9f8b0a94dda87b0bf8430a
        ```


    通过Git获取对应commit\_id的代码方法如下：
    
    ```
    git clone {repository_url}    # 克隆仓库的代码
    cd {repository_name}    # 切换到模型的代码仓目录
    git checkout  {branch}    # 切换到对应分支
    git reset --hard ｛commit_id｝     # 代码设置到对应的commit_id
    cd ｛code_path｝    # 切换到模型代码所在路径，若仓库下只有该模型，则无需切换
	
	_Official__（商用版）：在昇腾AI__处理器有良好的精度和性能表现_
	
默认配置
训练数据集预处理（以ImageNet-Train训练集为例，仅作为用户参考示例）：
图像的输入尺寸为224*224
图像输入格式：TFRecord
数据集大小：1281167
测试数据集预处理（以ImageNet-Val验证集为例，仅作为用户参考示例）：
图像的输入尺寸为224*224
图像输入格式：TFRecord
验证集大小：50000
训练超参（8卡）：
Batch size: 32
Momentum: 0.9
Loss_scale：1024
LR scheduler: cosine
Learning rate(LR): 0.1
Learning_rate_end: 0.000001
Warmup_epochs: 5Train epoch: 120

支持特性支持的特性包括：1、分布式训练。2、混合精度。3、数据并行。
8P训练脚本，支持数据并行的分布式训练。脚本样例中默认开启了混合精度，参考示例，见“开启混合精度”。
混合精度训练昇腾910 AI处理器提供自动混合精度功能，可以针对全网中float32数据类型的算子，按照内置的优化策略，自动将部分float32的算子降低精度到float16，从而在精度损失很小的情况下提升系统性能并减少内存使用。
当前昇腾910 AI处理器仅支持float32到float16的精度调整。使用自动混合精度功能后，推荐开启Loss Scaling，从而补偿降低精度带来的精度损失。
开启混合精度
脚本已默认开启混合精度，设置precision_mode参数的脚本参考如下。
run_config = NPURunConfig(        hcom_parallel=True,         precision_mode='allow_mix_precision',         enable_data_pre_proc=True,         save_checkpoints_steps=50000,         session_config=session_config,         model_dir = self.config['model_dir'],         iterations_per_loop=self.config['iterations_per_loop'],         keep_checkpoint_max=5        )


3 训练环境准备[TensorFlow]
硬件环境准备请参见各硬件产品文档。需要在硬件设备上安装与CANN版本配套的固件与驱动。
宿主机上需要安装Docker并登录Ascend Hub中心获取镜像。
当前模型支持的镜像列表如下表所示。

镜像名称：ARM架构：ascend-tensorflow-arm及x86 架构：ascend-tensorflow-x86
镜像版本：20.1.020.2.0
配套CANN版本:20.120.2
说明：对应配套华为企业业务网站 （ http://support.huawei.com ） “技术支持 > 昇腾计算 > 解决方案配套与软件 > CANN”的“V100R020C10V100R020C20”版本号。

4、快速上手
数据集准备请用户自行准备好数据集，包含训练集和验证集两部分，可选用的数据集包括ImageNet2012。
以ImageNet2012举例，训练集和验证集图片统一放到“data/resnext50/imagenet_TF”目录下。
模型训练
单击“立即下载”，下载源码包。
编译镜像。
docker build -t ascend-resnext50 .
启动容器实例。
bash docker_start.sh
容器启动脚本docker_start.sh参数说明如下：
#!/usr/bin/env bash
docker_image=$1 \#接受第一个参数作为docker_image
data_dir=$2 \#接受第二个参数作为训练数据集路径
model_dir=$3 \#接受第三个参数作为训练脚本路径
docker run -it --ipc=host \
        --device=/dev/davinci0 --device=/dev/davinci1 --device=/dev/davinci2 --device=/dev/davinci3 --device=/dev/davinci4 --device=/dev/davinci5 --device=/dev/davinci6 --device=/dev/davinci7 \  #docker使用卡数，当前使用0~7卡
 --device=/dev/davinci_manager --device=/dev/devmm_svm --device=/dev/hisi_hdc \
        -v /usr/local/Ascend/driver:/usr/local/Ascend/driver -v /usr/local/Ascend/add-ons/:/usr/local/Ascend/add-ons/ \
        -v ${data_dir}:${data_dir} \    #训练数据集路径
        -v ${model_dir}:${model_dir} \  #训练脚本路径
        -v /var/log/npu/conf/slog/slog.conf:/var/log/npu/conf/slog/slog.conf \
        -v /var/log/npu/slog/:/var/log/npu/slog -v /var/log/npu/profiling/:/var/log/npu/profiling \
        -v /var/log/npu/dump/:/var/log/npu/dump -v /var/log/npu/:/usr/slog ${docker_image} \#docker_image为镜像名称
        /bin/bash
执行docker_start.sh后带三个参数：

生成的docker_image
数据集路径
训练脚本路径
./docker_start.sh ${docker_image} ${data_dir} ${model_dir}

脚本运行。
容器场景
修改testscript目录下Resnext50_*_docker.sh文件，将对应容器镜像名修改为实际名称。
Resnext50_1p_docker.sh脚本文件
# user testcase
casecsv="case_resnext50.csv"
casenum=1

# docker or host
exectype="docker"

ostype=`uname -m`
if [ x"${ostype}" = xaarch64 ];
then
    # arm
    dockerImage="ubuntu_arm:18.04"
else
    # x86
    dockerImage="ubuntu:16.04"fi
	
Resnext50_8p_docker脚本文件
                   
# user testcase
casecsv="case_resnext50.csv"
casenum=8

# docker or host
exectype="docker"

ostype=`uname -m`
if [ x"${ostype}" = xaarch64 ];
then
    # arm
    dockerImage="ubuntu_arm:18.04"
else
    # x86
    dockerImage="ubuntu:16.04"
fi

配置环境变量。
启动训练之前，首先要配置程序运行相关环境变量。环境变量配置信息示例内容如下。
当版本为Atlas Data Center Solution V100R020C00时，请使用以下环境变量：
#!/bin/bash
export install_path=/usr/local/Ascend
export PATH=${install_path}/nnae/latest/fwkacllib/ccec_compiler/bin:${PATH}
export ASCEND_OPP_PATH=${install_path}/nnae/latest/opp
export PYTHONPATH=$PYTHONPATH:${install_path}/nnae/latest/opp/op_impl/built-in/ai_core/tbe:${install_path}/tfplugin/latest/tfplugin/python/site-packages/:${install_path}/nnae/latest/fwkacllib/python/site-packages/hccl:${install_path}/nnae/latest/fwkacllib/python/site-packages/te:${install_path}/nnae/latest/fwkacllib/python/site-packages/topi
export LD_LIBRARY_PATH=/usr/local/:/usr/local/lib/:/usr/lib/:${install_path}/nnae/latest/fwkacllib/lib64/:${install_path}/driver/lib64/common/:${install_path}/driver/lib64/driver/:${install_path}/add-ons
当版本为Atlas Data Center Solution V100R020C10时，请使用以下环境变量：

export install_path=/usr/local/Ascend/nnae/latest
# driver包依赖
export LD_LIBRARY_PATH=/usr/local/Ascend/driver/lib64/common/:/usr/local/Ascend/driver/lib64/driver:$LD_LIBRARY_PATH #仅容器训练场景配置
export LD_LIBRARY_PATH=/usr/local/Ascend/add-ons:$LD_LIBRARY_PATH
#fwkacllib 包依赖
export LD_LIBRARY_PATH=${install_path}/fwkacllib/lib64:$LD_LIBRARY_PATH
export 
PYTHONPATH=${install_path}/fwkacllib/python/site-packages:${install_path}/fwkacllib/python/site-packages/auto_tune.egg/auto_tune:${install_path}/fwkacllib/python/site-packages/schedule_search.egg:$PYTHONPATH
export
PATH=${install_path}/fwkacllib/ccec_compiler/bin:${install_path}/fwkacllib/bin:$PATH
#tfplugin 包依赖
export PYTHONPATH=/usr/local/Ascend/tfplugin/latest/tfplugin/python/site-packages:$PYTHONPATH
# opp包依赖
export ASCEND_OPP_PATH=${install_path}/opp

执行训练脚本。
1P训练指令（脚本位于testscript/Resnext50_1p_docker.sh）
./Resnext50_1p_docker.sh
8P训练指令（脚本位于testscript/Resnext50_8p_docker.sh）
./Resnext50_8p_docker.sh
物理机场景
修改case_resnext50_host.csv中，路径为脚本所在的绝对路径地址
/home/models/training_shop/03-code/ModelZoo_ResNext50_TF_MTI/code/resnext50_train/mains/res50.py
--model_dir=/home/models/training_shop/03-code/ModelZoo_ResNext50_TF_MTI/d_solution/ckpt${DEVICE_ID}
修改ModelZoo_ResNext50_TF_MTI\code\resnext50_train\configs 中res50_32bs_1p_host 和 res50_32bs_8p_host文件。
配置数据集的绝对路径地址
'data_url':  'file:///home/models/training_shop/03-code/ModelZoo_ResNext50_TF_MTI/data/resnext50/imagenet_TF',
配置checkpoint文件的路径
'ckpt_dir': '/home/models/training_shop/03-code/ModelZoo_ResNext50_TF_MTI/d_solution/ckpt0',
执行训练脚本
1P训练指令（脚本位于testscript/Resnext50_1p_host.sh）
./Resnext50_1p_host.sh
8P训练指令（脚本位于testscript/Resnext50_8p_host.sh）
./Resnext50_8p_host.sh

迁移学习指导
数据集准备。
数据集要求如下：
数据准备。
如果要使用自己的数据集，需要将数据集放到如下目录：
训练集： data\resnext50\
测试集： data\resnext50\
类别数可以通过训练参数中的num_classes来设置。
准确标注类别标签的数据集。
数据集每个类别所占比例大致相同。
数据集文件结构，请用户自行参照tfrecord脚本生成train/eval使用的TFRecord文件，包含训练集和验证集两部分，目录参考：
|--|imagenet_tfrecord
|   train-00000-of-01024
|   train-00001-of-01024
|   train-00002-of-01024
|   ...
|   validation-00000-of-00128
|   validation-00000-of-00128
|   ...
设置合理的数据集预处理方法（裁剪大小、随机翻转、标准化）。
def parse_and_preprocess_image_record(config, record, height, width,brightness, contrast, saturation, hue,
                                      distort, nsummary=10, increased_aug=False, random_search_aug=False):
		with tf.name_scope('preprocess_train'):
            image = crop_and_resize_image(config, record, height, width, distort)   #解码，80%中心抠图并且Resize[224 224]
            if distort:
                image = tf.image.random_flip_left_right(image)            #随机左右翻转
            image = tf.clip_by_value(image, 0., 255.)                     #归一化
    image = normalize(image)                  #减均值[121.0, 115.0, 100.0]，除方差[70.0, 68.0, 71.0]
    image = tf.cast(image, tf.float16)    return image

模型修改。
模型分类类别修改。
使用自有数据集进行分类，如需将分类类别修改为10。
修改code/resnext50_train/models/resnet50/resnet.py文件，将units=1001设置为units=10。
axes = [1,2]
x = tf.reduce_mean( x, axes, keepdims=True )
x = tf.identity(x, 'final_reduce_mean')
x = tf.reshape( x, [-1, 2048] )
x = tf.layers.dense(inputs=x, units=1001,kernel_initializer= tf.variance_scaling_initializer() )
.  .  .
x = tf.layers.dense(inputs=x, units=1001,kernel_initializer=tf.random_normal_initializer(stddev=0.01))
修改code/resnext50_train/models/resnet50/res50_model.py文件，将depth=1001设置为depth=10。
labels_one_hot = tf.one_hot(labels, depth=1001)
修改code/resnext50_train/configs/res50_32bs_1p_host.py文件，将num_classes=1001设置为num_classes=10。
'model_name': 'resnet50',
'num_classes': 1001,

加载预训练模型。
配置文件增加参数，修改code/resnext50_train/configs/res50_32bs_1p_host.py文件（具体配置文件名称，用户根据自己实际名称设置），增加以下参数。
'restore_path': '/code/ckpt0/model.ckpt-601000',  #用户根据预训练的实际ckpt进行配置
'restore_exclude': ['fp32_vars/dense'],   #不加载预训练网络中FC层权重
模型加载修改，修改code/resnext50_train/models/resnet50/res50_model.py文件，增加以下代码行。
#restore ckpt for finetune，
variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=self.config.get('restore_exclude'))
tf.train.init_from_checkpoint(self.config.get('restore_path'),{v.name.split(':')[0]: v for v in variables_to_restore})
模型训练。请参考“模型训练”。


6、高级参考
脚本和示例代码         
├── code
│   ├──resnext50_train                    //训练脚本代码
├── bin                         
│   ├──npu_set_env                      //环境变量配置脚本 
├── testscript                         
│   ├──Resnext50_1p_docker.sh                  //容器场景：1P执行脚本
│   ├──Resnext50_8p_docker.sh                  //容器场景：8P执行脚本
│   ├──Resnext50_1p_host.sh                  //物理机场景：1P执行脚本
│   ├──Resnext50_8p_host.sh                  //物理机场景：8P执行脚本
├── case_resnext50                          //容器场景：测试用例配置
├── case_resnext50_host                     //物理机场景：测试用例配置脚本参数
--rank_size              使用NPU卡数量，默认：单P 配置1，8P 配置8
--mode                   运行模式，默认train；可选：train，evaluate
--max_train_steps        训练次数，单P 默认：10000
--iterations_per_loop    NPU运行时，device端下沉次数，默认：1000
--eval                   训练结束后，是否启动验证流程。默认：单P False，8P True
--num_epochs             训练epoch次数， 默认：单P None，8P 120 
--data_url               数据集路径，默认：data/resnext50/imagenet_TF
--ckpt_dir               验证时checkpoint文件地址 默认：/d_solution/ckpt0
--lr_decay_mode          学习率方式，默认：cosine  
--learning_rate_maximum  初始学习率，默认：0.1
--learning_rate_end      结束学习率：默认：0.000001
--batch_size             每个NPU的batch size，默认：32
--warmup_epochs          初始warmup训练epoch数，默认：5
--momentum               动量，默认：0.9
说明：当前默认模式为train，iterations_per_loop配置1000，每训练1000step会在日志中打印出 loss，FPS，和lr。在8P训练脚本中，配置了eval=True，当训练结束后，会进行验证流程，输出精度验证结果。

训练过程通过“模型训练”中的训练指令启动单卡或者多卡训练。单卡和多卡通过运行不同脚本，支持1，8P网络训练。训练执行过程中，会输出step，FPS，loss到如下路径。
/result/cloud-localhost-*-0/0/resnet50_train/results/res50_32bs_1p
Step   Epoch   Speed   Loss   FinLoss   LR
step:  1000  epoch:  0.0  FPS:  180.0  loss: 6.797  total_loss: 8.258  lr:0.1000000
step:  2000  epoch:  0.0  FPS:  741.5  loss: 6.766  total_loss: 7.980  lr:0.1000000
step:  3000  epoch:  0.1  FPS:  741.5  loss: 6.707  total_loss: 7.730  lr:0.1000000
step:  4000  epoch:  0.1  FPS:  741.3  loss: 6.496  total_loss: 7.367  lr:0.1000000
step:  5000  epoch:  0.1  FPS:  741.4  loss: 6.410  total_loss: 7.164  lr:0.1000000
step:  6000  epoch:  0.1  FPS:  741.4  loss: 6.148  total_loss: 6.812  lr:0.1000000
step:  7000  epoch:  0.2  FPS:  741.2  loss: 5.910  total_loss: 6.504  lr:0.1000000
step:  8000  epoch:  0.2  FPS:  741.5  loss: 6.117  total_loss: 6.656  lr:0.1000000
验证/推理过程
通过“模型训练”中的测试指令启动8P测试。在120 epoch训练执行完成后，脚本会自动执行验证流程。验证结果会输出到 /result/cloud-localhost-*-0/0/resnet50_train/results/res50_32bs_8p目录中。
测试结束后会打印验证集的top1 accuracy和top5 accuracy，如下所示。
Evaluating
Validation dataset size: 50000
 step  epoch  top1    top5     loss   checkpoint_time(UTC)
226000   46.0  61.611   84.63    2.55  2020-06-21 01:33:11
339000   68.0  67.316   88.64    2.42  2020-06-21 01:33:12
452000   91.0  72.931   91.71    2.26  2020-06-21 01:33:12
565000  113.0  77.869   93.99    2.17  2020-06-21 01:33:11
601000  121.0  78.197   94.14    2.18  2020-06-21 01:33:11
Finished evaluation