# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

# Pull request against these branches will trigger this build
pr:
- master
- staging

#Any commit to this branch will trigger the build.
trigger:
- staging
- master

variables:
- group: LinuxAgentPool

jobs:
- job: unit
  displayName: 'Unit tests Linux PySpark on notebooks'
  timeoutInMinutes: 20 # how long to run the job before automatically cancelling
  pool:
    name: $(Agent_Pool)

  steps:
  - bash: |
      echo "##vso[task.prependpath]/data/anaconda/bin"
      conda env list
    displayName: Add Conda to PATH
  
  # Uncomment if needed
  # Conda creation can take around 10min
  # - bash: |
  #     python tools/generate_conda_file.py  --pyspark
  #     conda env update -n reco_pyspark -f reco_pyspark.yaml
  #   displayName: 'Creating Conda Environment with dependencies'

  - script: |
      . /anaconda/etc/profile.d/conda.sh && \
      conda activate reco_pyspark && \
      pytest tests/unit --durations 0 -m "notebooks and spark and not gpu" --junitxml=reports/test-unit.xml
    displayName: 'Run Tests'
    env:
      PYSPARK_PYTHON: /anaconda/envs/reco_pyspark/bin/python
      PYSPARK_DRIVER_PYTHON: /anaconda/envs/reco_pyspark/bin/python

  - task: PublishTestResults@2
    displayName: 'Publish Test Results **/test-*.xml'
    inputs:
      testResultsFiles: '**/test-*.xml'
      failTaskOnFailedTests: true
    condition: succeededOrFailed()

  # Uncomment if needed
  # - script: |
  #     conda env remove -n reco_pyspark -y   
  #   workingDirectory: tests
  #   displayName: 'Conda remove'
  #   continueOnError: true
  #   condition: succeededOrFailed()
  
  