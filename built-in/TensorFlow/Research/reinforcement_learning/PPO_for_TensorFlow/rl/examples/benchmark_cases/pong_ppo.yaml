alg_para:
  alg_name: PPO

env_para:
  env_name: AtariEnv
  env_info: { 'name': PongNoFrameskip-v4, 'vision': False}

agent_para:
  agent_name: AtariPpo
  agent_num : 1
  agent_config: {
    'max_steps': 200,
    'complete_step': 10000000
    }

model_para:
  actor:
    model_name: PpoCnn
    state_dim: [84,84,4]
    action_dim: 6
    model_config: {
      'LR': 0.00025,
      'LOSS_CLIPPING': 0.1,
      'ENTROPY_LOSS': 0.01,
      }


model_name: pong_ppo_0515
env_num: 10
node_config: [["127.0.0.1", "username", "passwd"],
              ]
# test_node_config: [["127.0.0.1", "username", "passwd"],
#               ]

benchmark:
  eval:
    gap: 80
    max_step_per_episode: 2000
